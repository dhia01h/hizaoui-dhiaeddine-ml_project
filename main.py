import argparse
import numpy as np
import os
import mlflow
import mlflow.sklearn
from model_pipeline import (
    prepare_data,
    train_model,
    evaluate_model,
    save_model,
    load_model,
)
from mlflow.tracking import MlflowClient
from mlflow_utils import (
    get_elasticsearch_client,
    log_to_elasticsearch,
)  # ğŸ”¥ Importer Elasticsearch

# ğŸ“Œ Configuration de MLflow
TRACKING_URI = "http://localhost:5000"  # âœ… VÃ©rifie bien que MLflow tourne sur ce port
EXPERIMENT_NAME = "Churn Prediction Experiment"

mlflow.set_tracking_uri(TRACKING_URI)
client = MlflowClient()

# ğŸ“Œ VÃ©rifier si l'expÃ©rience MLflow existe, sinon la crÃ©er
experiment = client.get_experiment_by_name(EXPERIMENT_NAME)
if experiment is None:
    print(f"âš ï¸ ExpÃ©rience '{EXPERIMENT_NAME}' non trouvÃ©e, crÃ©ation en cours...")
    experiment_id = client.create_experiment(EXPERIMENT_NAME)
    print(f"âœ… ExpÃ©rience crÃ©Ã©e avec ID : {experiment_id}")
else:
    experiment_id = experiment.experiment_id
    print(f"ğŸ”„ ExpÃ©rience existante trouvÃ©e : ID {experiment_id}")

mlflow.set_experiment(EXPERIMENT_NAME)

# ğŸ“Œ Connexion Ã  Elasticsearch
es = get_elasticsearch_client()
if es is None:
    print("âš ï¸ Elasticsearch est injoignable, les logs ne seront pas envoyÃ©s.")


def register_model(run_id, model, X_train):
    """
    Enregistre le modÃ¨le dans la Model Registry de MLflow avec un exemple d'entrÃ©e.
    """
    model_uri = f"runs:/{run_id}/model"
    input_example = np.array([X_train[0]])

    try:
        mlflow.sklearn.log_model(model, "model", input_example=input_example)
        registered_model = mlflow.register_model(model_uri, "ChurnPredictionModel")
        print(f"âœ… ModÃ¨le enregistrÃ© dans la Model Registry : {registered_model}")
    except Exception as e:
        print(f"âŒ Erreur lors de l'enregistrement du modÃ¨le : {e}")


def main():
    parser = argparse.ArgumentParser(description="Pipeline Churn avec MLflow")
    parser.add_argument(
        "--data", type=str, default="churn-bigml-80.csv", help="Chemin du fichier CSV"
    )
    parser.add_argument("--train", action="store_true", help="EntraÃ®ner le modÃ¨le")
    parser.add_argument("--evaluate", action="store_true", help="Ã‰valuer le modÃ¨le")
    parser.add_argument(
        "--save",
        type=str,
        default="random_forest.pkl",
        help="Nom du fichier pour sauvegarder le modÃ¨le",
    )
    parser.add_argument("--load", type=str, help="Charger un modÃ¨le sauvegardÃ©")

    args = parser.parse_args()

    print("ğŸ“‚ Chargement des donnÃ©es...")
    X_train, X_test, y_train, y_test, scaler = prepare_data(args.data)
    model = None

    # ğŸ“Œ VÃ©rifier si le modÃ¨le Ã  charger existe
    if args.load and not os.path.exists(args.load):
        print(f"âŒ Fichier modÃ¨le '{args.load}' non trouvÃ©. VÃ©rifiez le chemin.")
        return

    # ğŸ“Œ DÃ©marrer un run MLflow
    with mlflow.start_run(experiment_id=experiment_id) as run:
        run_id = run.info.run_id
        mlflow.log_param("data_file", args.data)

        if args.load:
            print(f"ğŸ”„ Chargement du modÃ¨le depuis {args.load}...")
            model = load_model(args.load)
            if model is None:
                print("âŒ Erreur : Impossible de charger le modÃ¨le.")
                return
            print("âœ… ModÃ¨le chargÃ© avec succÃ¨s !")

        if args.train:
            print("ğŸš€ EntraÃ®nement du modÃ¨le en cours...")
            model = train_model(X_train, y_train)
            if model is None:
                print("âŒ Erreur : L'entraÃ®nement du modÃ¨le a Ã©chouÃ©.")
                return
            print("âœ… ModÃ¨le entraÃ®nÃ© avec succÃ¨s !")

            register_model(run_id, model, X_train)
            if args.save:
                save_model(model, args.save)
                print(f"ğŸ’¾ ModÃ¨le sauvegardÃ© sous {args.save}")

        if args.evaluate:
            if model is None:
                print(
                    "âš ï¸ Aucun modÃ¨le trouvÃ© ! Veuillez en entraÃ®ner un ou en charger un."
                )
            else:
                print("ğŸ“Š Ã‰valuation du modÃ¨le en cours...")
                metrics = evaluate_model(model, X_test, y_test)

                for metric, value in metrics.items():
                    mlflow.log_metric(metric, value)
                    print(
                        f"ğŸ“¤ Envoi de la mÃ©trique {metric}: {value} Ã  Elasticsearch..."
                    )  # ğŸ” Debug
                    try:
                        log_to_elasticsearch(es, run_id, metric, value)
                    except Exception as e:
                        print(f"âš ï¸ Impossible d'envoyer {metric} Ã  Elasticsearch : {e}")


if __name__ == "__main__":
    main()
